version: '3'
services:
    postgres:
        image: postgres:13
        container_name: postgres
        restart: always
        environment:
            - POSTGRES_USER=airflow
            - POSTGRES_PASSWORD=example_pw
            - POSTGRES_HOST=postgres
            - POSTGRES_DB=airflow
        expose:
            - 5432
        volumes:
            - 'db_data:/var/lib/postgresql/data'

    dbtpostgres:
        image: postgres:13
        container_name: dbtpostgres
        restart: always
        environment:
            - POSTGRES_USER=dbt
            - POSTGRES_PASSWORD=example_pw
            - POSTGRES_HOST=postgres
            - POSTGRES_DB=dbt
        ports:
            - 5432:5432
        volumes:
            - 'dbt_data:/var/lib/postgresql/data'

    redis:
        image: redis:6.0
        container_name: redis
        restart: always
        environment:
            - REDIS_HOST=redis
            - REDIS_PORT=6379
        expose:
            - 6379

    webserver:
        build: .
        container_name: webserver
        user: airflow
        restart: always
        environment:
            - EXECUTOR=CeleryExecutor
        depends_on:
            - postgres
            - redis
        ports:
            - 8080:8080
        volumes:
          - ./dags:/airflow/dags
          - ./dwh:/airflow/dwh
        command: sh -c "sleep 5 && cd dwh && dbt seed && cd .. && airflow db init && airflow users create --role Admin --username admin --email admin@dairflow.com --firstname admin --lastname admin --password admin && airflow webserver"

    scheduler:
        build: .
        container_name: scheduler
        user: airflow
        restart: always
        environment:
            - EXECUTOR=CeleryExecutor
        depends_on:
            - webserver
        volumes:
          - ./dags:/airflow/dags
          - ./dwh:/airflow/dwh
        command: sh -c "sleep 10 && airflow scheduler"

    worker:
        build: .
        user: airflow
        restart: always
        environment:
            - EXECUTOR=CeleryExecutor
        depends_on:
            - scheduler
        expose:
            - 8793
        volumes:
          - ./dags:/airflow/dags
          - ./dwh:/airflow/dwh
        command: sh -c "sleep 10 && airflow celery worker"

volumes:
    db_data:
    dbt_data:
